{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(r\"D:\\fine tuning llm\\code\\LLaMA-Factory-repo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MY_BahUTqW3G",
    "outputId": "c8183540-1247-401c-941a-cd3003b71638"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\fine tuning llm\\code\\LLaMA-Factory-repo\\LLaMA-Factory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'LLaMA-Factory' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git\n",
    "    \n",
    "%cd LLaMA-Factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "taqxxnUprTaP",
    "outputId": "f2ed3955-04fa-4450-d6e1-d1949f366916"
   },
   "outputs": [],
   "source": [
    "# ! pip install bitsandbytes peft\n",
    "# ! pip install mistral_inference\n",
    "# ! pip install -e \".[torch,metrics]\"\n",
    "# ! pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "V9PFGYU82bDx",
    "outputId": "98eab68c-74c4-4a1e-b1e1-73d969038668"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\fine tuning llm\\\\code\\\\LLaMA-Factory-repo\\\\LLaMA-Factory'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3uZvi5wqoh_W",
    "outputId": "793dc0f8-b8bb-491e-fc0b-6fd8a9f48577"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to C:\\Users\\ammar\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"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\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5oqlGx1vSHI4",
    "outputId": "255b0d6e-26fb-4a12-f70a-8b31a98c5249"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K-ueoxHOtwPk",
    "outputId": "577d51b0-8757-477a-e9b3-2dfe4f2452f0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'CUDA_VISIBLE_DEVICES' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# !CUDA_VISIBLE_DEVICES=0 python src/webui.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('agg')  # Or another compatible backend like 'tkagg', 'qt5agg', etc.\n",
    "import os\n",
    "os.environ['MPLBACKEND'] = 'agg'  # Or another compatible backend\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Mpys9BOHroRT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-05 07:04:50.174091: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-05 07:05:21.919069: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ammar\\anaconda3\\envs\\llm\\lib\\site-packages\\transformers\\activations_tf.py\", line 22, in <module>\n",
      "    import tf_keras as keras\n",
      "ModuleNotFoundError: No module named 'tf_keras'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ammar\\anaconda3\\envs\\llm\\lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1560, in _get_module\n",
      "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
      "  File \"C:\\Users\\ammar\\anaconda3\\envs\\llm\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\ammar\\anaconda3\\envs\\llm\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 38, in <module>\n",
      "    from .activations_tf import get_tf_activation\n",
      "  File \"C:\\Users\\ammar\\anaconda3\\envs\\llm\\lib\\site-packages\\transformers\\activations_tf.py\", line 27, in <module>\n",
      "    raise ValueError(\n",
      "ValueError: Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ammar\\anaconda3\\envs\\llm\\lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1560, in _get_module\n",
      "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
      "  File \"C:\\Users\\ammar\\anaconda3\\envs\\llm\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\ammar\\anaconda3\\envs\\llm\\lib\\site-packages\\transformers\\integrations\\integration_utils.py\", line 35, in <module>\n",
      "    from .. import PreTrainedModel, TFPreTrainedModel\n",
      "  File \"<frozen importlib._bootstrap>\", line 1075, in _handle_fromlist\n",
      "  File \"C:\\Users\\ammar\\anaconda3\\envs\\llm\\lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1550, in __getattr__\n",
      "    module = self._get_module(self._class_to_module[name])\n",
      "  File \"C:\\Users\\ammar\\anaconda3\\envs\\llm\\lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1562, in _get_module\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Failed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\n",
      "Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\fine tuning llm\\code\\LLaMA-Factory-repo\\LLaMA-Factory\\src\\webui.py\", line 17, in <module>\n",
      "    from llamafactory.webui.interface import create_ui\n",
      "  File \"D:\\fine tuning llm\\code\\LLaMA-Factory-repo\\LLaMA-Factory\\src\\llamafactory\\__init__.py\", line 17, in <module>\n",
      "    from .cli import VERSION\n",
      "  File \"D:\\fine tuning llm\\code\\LLaMA-Factory-repo\\LLaMA-Factory\\src\\llamafactory\\cli.py\", line 21, in <module>\n",
      "    from . import launcher\n",
      "  File \"D:\\fine tuning llm\\code\\LLaMA-Factory-repo\\LLaMA-Factory\\src\\llamafactory\\launcher.py\", line 15, in <module>\n",
      "    from llamafactory.train.tuner import run_exp\n",
      "  File \"D:\\fine tuning llm\\code\\LLaMA-Factory-repo\\LLaMA-Factory\\src\\llamafactory\\train\\tuner.py\", line 28, in <module>\n",
      "    from .dpo import run_dpo\n",
      "  File \"D:\\fine tuning llm\\code\\LLaMA-Factory-repo\\LLaMA-Factory\\src\\llamafactory\\train\\dpo\\__init__.py\", line 15, in <module>\n",
      "    from .workflow import run_dpo\n",
      "  File \"D:\\fine tuning llm\\code\\LLaMA-Factory-repo\\LLaMA-Factory\\src\\llamafactory\\train\\dpo\\workflow.py\", line 22, in <module>\n",
      "    from ...extras.ploting import plot_loss\n",
      "  File \"D:\\fine tuning llm\\code\\LLaMA-Factory-repo\\LLaMA-Factory\\src\\llamafactory\\extras\\ploting.py\", line 20, in <module>\n",
      "    from transformers.trainer import TRAINER_STATE_NAME\n",
      "  File \"C:\\Users\\ammar\\anaconda3\\envs\\llm\\lib\\site-packages\\transformers\\trainer.py\", line 41, in <module>\n",
      "    from .integrations import (\n",
      "  File \"<frozen importlib._bootstrap>\", line 1075, in _handle_fromlist\n",
      "  File \"C:\\Users\\ammar\\anaconda3\\envs\\llm\\lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1550, in __getattr__\n",
      "    module = self._get_module(self._class_to_module[name])\n",
      "  File \"C:\\Users\\ammar\\anaconda3\\envs\\llm\\lib\\site-packages\\transformers\\utils\\import_utils.py\", line 1562, in _get_module\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Failed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\n",
      "Failed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\n",
      "Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.\n"
     ]
    }
   ],
   "source": [
    "!python src\\webui.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
