{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T16:24:47.491139Z",
     "iopub.status.busy": "2024-07-01T16:24:47.490775Z",
     "iopub.status.idle": "2024-07-01T16:25:17.638260Z",
     "shell.execute_reply": "2024-07-01T16:25:17.637266Z",
     "shell.execute_reply.started": "2024-07-01T16:24:47.491110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "kaggle-environments 1.14.11 requires transformers>=4.33.1, but you have transformers 4.31.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 transformers==4.31.0 trl==0.4.7 einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T16:25:17.640579Z",
     "iopub.status.busy": "2024-07-01T16:25:17.640291Z",
     "iopub.status.idle": "2024-07-01T16:25:17.646753Z",
     "shell.execute_reply": "2024-07-01T16:25:17.645795Z",
     "shell.execute_reply.started": "2024-07-01T16:25:17.640540Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T18:02:39.291762Z",
     "iopub.status.busy": "2024-07-01T18:02:39.291406Z",
     "iopub.status.idle": "2024-07-01T18:02:40.713944Z",
     "shell.execute_reply": "2024-07-01T18:02:40.713138Z",
     "shell.execute_reply.started": "2024-07-01T18:02:39.291734Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig, \n",
    "    HfArgumentParser,\n",
    "    TrainingArguments, \n",
    "    pipeline,\n",
    "    logging,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T16:25:36.788986Z",
     "iopub.status.busy": "2024-07-01T16:25:36.788575Z",
     "iopub.status.idle": "2024-07-01T16:25:36.979395Z",
     "shell.execute_reply": "2024-07-01T16:25:36.978613Z",
     "shell.execute_reply.started": "2024-07-01T16:25:36.788946Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T16:25:36.981214Z",
     "iopub.status.busy": "2024-07-01T16:25:36.980569Z",
     "iopub.status.idle": "2024-07-01T16:25:36.990134Z",
     "shell.execute_reply": "2024-07-01T16:25:36.989083Z",
     "shell.execute_reply.started": "2024-07-01T16:25:36.981176Z"
    }
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import interpreter_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T16:25:36.991571Z",
     "iopub.status.busy": "2024-07-01T16:25:36.991240Z",
     "iopub.status.idle": "2024-07-01T16:25:53.549754Z",
     "shell.execute_reply": "2024-07-01T16:25:53.548585Z",
     "shell.execute_reply.started": "2024-07-01T16:25:36.991545Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
      "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
      "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
      "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
      "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
      "\n",
      "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your token (input will not be visible):  ·····································\n",
      "Add token as git credential? (Y/n)  Y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: write).\n",
      "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
      "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
      "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
      "\n",
      "git config --global credential.helper store\n",
      "\n",
      "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
      "Token has not been saved to git credential helper.\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "interpreter_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T16:25:53.551491Z",
     "iopub.status.busy": "2024-07-01T16:25:53.551122Z",
     "iopub.status.idle": "2024-07-01T16:25:55.740745Z",
     "shell.execute_reply": "2024-07-01T16:25:55.739826Z",
     "shell.execute_reply.started": "2024-07-01T16:25:53.551456Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9602caafc01349baa152d212e56260a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/2.82k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d18be8720f6d4ca69b1ef289564752b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/4.79M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ec32d39879246dfb8fefa6d3d5e710d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/3512 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Context', 'Response'],\n",
       "    num_rows: 3512\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_name = \"Amod/mental_health_counseling_conversations\"\n",
    "\n",
    "dataset = load_dataset(data_name, split=\"train\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T16:25:55.742261Z",
     "iopub.status.busy": "2024-07-01T16:25:55.741967Z",
     "iopub.status.idle": "2024-07-01T16:25:55.746367Z",
     "shell.execute_reply": "2024-07-01T16:25:55.745385Z",
     "shell.execute_reply.started": "2024-07-01T16:25:55.742237Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T16:25:55.748097Z",
     "iopub.status.busy": "2024-07-01T16:25:55.747764Z",
     "iopub.status.idle": "2024-07-01T16:25:55.926442Z",
     "shell.execute_reply": "2024-07-01T16:25:55.925514Z",
     "shell.execute_reply.started": "2024-07-01T16:25:55.748072Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>If everyone thinks you're worthless, then mayb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>Hello, and thank you for your question and see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>First thing I'd suggest is getting the sleep y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>Therapy is essential for those that are feelin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>I first want to let you know that you are not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3507</th>\n",
       "      <td>My grandson's step-mother sends him to school ...</td>\n",
       "      <td>Absolutely not! It is never in a child's best ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3508</th>\n",
       "      <td>My boyfriend is in recovery from drug addictio...</td>\n",
       "      <td>I'm sorry you have tension between you and you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3509</th>\n",
       "      <td>The birth mother attempted suicide several tim...</td>\n",
       "      <td>The true answer is, \"no one can really say wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3510</th>\n",
       "      <td>I think adult life is making him depressed and...</td>\n",
       "      <td>How do you help yourself to believe you requir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3511</th>\n",
       "      <td>I just took a job that requires me to travel f...</td>\n",
       "      <td>hmm this is a tough one!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3512 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Context  \\\n",
       "0     I'm going through some things with my feelings...   \n",
       "1     I'm going through some things with my feelings...   \n",
       "2     I'm going through some things with my feelings...   \n",
       "3     I'm going through some things with my feelings...   \n",
       "4     I'm going through some things with my feelings...   \n",
       "...                                                 ...   \n",
       "3507  My grandson's step-mother sends him to school ...   \n",
       "3508  My boyfriend is in recovery from drug addictio...   \n",
       "3509  The birth mother attempted suicide several tim...   \n",
       "3510  I think adult life is making him depressed and...   \n",
       "3511  I just took a job that requires me to travel f...   \n",
       "\n",
       "                                               Response  \n",
       "0     If everyone thinks you're worthless, then mayb...  \n",
       "1     Hello, and thank you for your question and see...  \n",
       "2     First thing I'd suggest is getting the sleep y...  \n",
       "3     Therapy is essential for those that are feelin...  \n",
       "4     I first want to let you know that you are not ...  \n",
       "...                                                 ...  \n",
       "3507  Absolutely not! It is never in a child's best ...  \n",
       "3508  I'm sorry you have tension between you and you...  \n",
       "3509  The true answer is, \"no one can really say wit...  \n",
       "3510  How do you help yourself to believe you requir...  \n",
       "3511                           hmm this is a tough one!  \n",
       "\n",
       "[3512 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dataset)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T16:25:55.931507Z",
     "iopub.status.busy": "2024-07-01T16:25:55.930750Z",
     "iopub.status.idle": "2024-07-01T16:25:55.937226Z",
     "shell.execute_reply": "2024-07-01T16:25:55.936308Z",
     "shell.execute_reply.started": "2024-07-01T16:25:55.931475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3512, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T16:25:55.938953Z",
     "iopub.status.busy": "2024-07-01T16:25:55.938520Z",
     "iopub.status.idle": "2024-07-01T16:25:55.964679Z",
     "shell.execute_reply": "2024-07-01T16:25:55.963590Z",
     "shell.execute_reply.started": "2024-07-01T16:25:55.938921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3512 entries, 0 to 3511\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Context   3512 non-null   object\n",
      " 1   Response  3512 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 55.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T16:25:55.966189Z",
     "iopub.status.busy": "2024-07-01T16:25:55.965901Z",
     "iopub.status.idle": "2024-07-01T16:25:55.981443Z",
     "shell.execute_reply": "2024-07-01T16:25:55.980526Z",
     "shell.execute_reply.started": "2024-07-01T16:25:55.966164Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Context     0\n",
       "Response    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T16:25:55.983045Z",
     "iopub.status.busy": "2024-07-01T16:25:55.982674Z",
     "iopub.status.idle": "2024-07-01T16:25:55.991075Z",
     "shell.execute_reply": "2024-07-01T16:25:55.990067Z",
     "shell.execute_reply.started": "2024-07-01T16:25:55.983017Z"
    }
   },
   "outputs": [],
   "source": [
    "def format_row(row):\n",
    "    question = row[\"Context\"]\n",
    "    answer = row[\"Response\"]\n",
    "    formatted_str = f\"[INST] {question} [/INST] {answer}\"\n",
    "    return formatted_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T16:25:55.992542Z",
     "iopub.status.busy": "2024-07-01T16:25:55.992249Z",
     "iopub.status.idle": "2024-07-01T16:25:56.060532Z",
     "shell.execute_reply": "2024-07-01T16:25:56.059618Z",
     "shell.execute_reply.started": "2024-07-01T16:25:55.992518Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [INST] I'm going through some things with my f...\n",
       "1       [INST] I'm going through some things with my f...\n",
       "2       [INST] I'm going through some things with my f...\n",
       "3       [INST] I'm going through some things with my f...\n",
       "4       [INST] I'm going through some things with my f...\n",
       "                              ...                        \n",
       "3507    [INST] My grandson's step-mother sends him to ...\n",
       "3508    [INST] My boyfriend is in recovery from drug a...\n",
       "3509    [INST] The birth mother attempted suicide seve...\n",
       "3510    [INST] I think adult life is making him depres...\n",
       "3511    [INST] I just took a job that requires me to t...\n",
       "Name: formatted, Length: 3512, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"formatted\"] = df.apply(format_row, axis=1)\n",
    "df[\"formatted\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T16:25:56.062299Z",
     "iopub.status.busy": "2024-07-01T16:25:56.061930Z",
     "iopub.status.idle": "2024-07-01T16:25:56.076967Z",
     "shell.execute_reply": "2024-07-01T16:25:56.075972Z",
     "shell.execute_reply.started": "2024-07-01T16:25:56.062266Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Response</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>If everyone thinks you're worthless, then mayb...</td>\n",
       "      <td>[INST] I'm going through some things with my f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>Hello, and thank you for your question and see...</td>\n",
       "      <td>[INST] I'm going through some things with my f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>First thing I'd suggest is getting the sleep y...</td>\n",
       "      <td>[INST] I'm going through some things with my f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>Therapy is essential for those that are feelin...</td>\n",
       "      <td>[INST] I'm going through some things with my f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm going through some things with my feelings...</td>\n",
       "      <td>I first want to let you know that you are not ...</td>\n",
       "      <td>[INST] I'm going through some things with my f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3507</th>\n",
       "      <td>My grandson's step-mother sends him to school ...</td>\n",
       "      <td>Absolutely not! It is never in a child's best ...</td>\n",
       "      <td>[INST] My grandson's step-mother sends him to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3508</th>\n",
       "      <td>My boyfriend is in recovery from drug addictio...</td>\n",
       "      <td>I'm sorry you have tension between you and you...</td>\n",
       "      <td>[INST] My boyfriend is in recovery from drug a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3509</th>\n",
       "      <td>The birth mother attempted suicide several tim...</td>\n",
       "      <td>The true answer is, \"no one can really say wit...</td>\n",
       "      <td>[INST] The birth mother attempted suicide seve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3510</th>\n",
       "      <td>I think adult life is making him depressed and...</td>\n",
       "      <td>How do you help yourself to believe you requir...</td>\n",
       "      <td>[INST] I think adult life is making him depres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3511</th>\n",
       "      <td>I just took a job that requires me to travel f...</td>\n",
       "      <td>hmm this is a tough one!</td>\n",
       "      <td>[INST] I just took a job that requires me to t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3512 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Context  \\\n",
       "0     I'm going through some things with my feelings...   \n",
       "1     I'm going through some things with my feelings...   \n",
       "2     I'm going through some things with my feelings...   \n",
       "3     I'm going through some things with my feelings...   \n",
       "4     I'm going through some things with my feelings...   \n",
       "...                                                 ...   \n",
       "3507  My grandson's step-mother sends him to school ...   \n",
       "3508  My boyfriend is in recovery from drug addictio...   \n",
       "3509  The birth mother attempted suicide several tim...   \n",
       "3510  I think adult life is making him depressed and...   \n",
       "3511  I just took a job that requires me to travel f...   \n",
       "\n",
       "                                               Response  \\\n",
       "0     If everyone thinks you're worthless, then mayb...   \n",
       "1     Hello, and thank you for your question and see...   \n",
       "2     First thing I'd suggest is getting the sleep y...   \n",
       "3     Therapy is essential for those that are feelin...   \n",
       "4     I first want to let you know that you are not ...   \n",
       "...                                                 ...   \n",
       "3507  Absolutely not! It is never in a child's best ...   \n",
       "3508  I'm sorry you have tension between you and you...   \n",
       "3509  The true answer is, \"no one can really say wit...   \n",
       "3510  How do you help yourself to believe you requir...   \n",
       "3511                           hmm this is a tough one!   \n",
       "\n",
       "                                                   text  \n",
       "0     [INST] I'm going through some things with my f...  \n",
       "1     [INST] I'm going through some things with my f...  \n",
       "2     [INST] I'm going through some things with my f...  \n",
       "3     [INST] I'm going through some things with my f...  \n",
       "4     [INST] I'm going through some things with my f...  \n",
       "...                                                 ...  \n",
       "3507  [INST] My grandson's step-mother sends him to ...  \n",
       "3508  [INST] My boyfriend is in recovery from drug a...  \n",
       "3509  [INST] The birth mother attempted suicide seve...  \n",
       "3510  [INST] I think adult life is making him depres...  \n",
       "3511  [INST] I just took a job that requires me to t...  \n",
       "\n",
       "[3512 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(columns = {\"formatted\": \"text\"}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T16:25:56.078992Z",
     "iopub.status.busy": "2024-07-01T16:25:56.078536Z",
     "iopub.status.idle": "2024-07-01T16:25:56.087268Z",
     "shell.execute_reply": "2024-07-01T16:25:56.086465Z",
     "shell.execute_reply.started": "2024-07-01T16:25:56.078952Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[[\"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T16:25:56.088915Z",
     "iopub.status.busy": "2024-07-01T16:25:56.088469Z",
     "iopub.status.idle": "2024-07-01T16:25:56.102697Z",
     "shell.execute_reply": "2024-07-01T16:25:56.101748Z",
     "shell.execute_reply.started": "2024-07-01T16:25:56.088876Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[INST] I'm going through some things with my f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[INST] I'm going through some things with my f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[INST] I'm going through some things with my f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[INST] I'm going through some things with my f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[INST] I'm going through some things with my f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  [INST] I'm going through some things with my f...\n",
       "1  [INST] I'm going through some things with my f...\n",
       "2  [INST] I'm going through some things with my f...\n",
       "3  [INST] I'm going through some things with my f...\n",
       "4  [INST] I'm going through some things with my f..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T16:25:56.104307Z",
     "iopub.status.busy": "2024-07-01T16:25:56.103832Z",
     "iopub.status.idle": "2024-07-01T16:25:56.316212Z",
     "shell.execute_reply": "2024-07-01T16:25:56.315025Z",
     "shell.execute_reply.started": "2024-07-01T16:25:56.104280Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"/kaggle/working/data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T16:25:56.317693Z",
     "iopub.status.busy": "2024-07-01T16:25:56.317377Z",
     "iopub.status.idle": "2024-07-01T16:25:56.650651Z",
     "shell.execute_reply": "2024-07-01T16:25:56.649760Z",
     "shell.execute_reply.started": "2024-07-01T16:25:56.317663Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1952e1da1446409db82e8e46a9b63172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 3512\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset = load_dataset(\"csv\", data_files=\"/kaggle/working/data.csv\", split=\"train\")\n",
    "training_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T16:25:56.652179Z",
     "iopub.status.busy": "2024-07-01T16:25:56.651847Z",
     "iopub.status.idle": "2024-07-01T16:25:58.235345Z",
     "shell.execute_reply": "2024-07-01T16:25:58.234520Z",
     "shell.execute_reply.started": "2024-07-01T16:25:56.652151Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c89445532a2348f7ae33ee71f5164b03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/7.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e751604089004de0ac8ae9f805c59f07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "113c815a38ad4a3087f8753a7f0f9822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88c0a5a2706f4268b5805f1346652899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bf271d7eb2a41828fbc5ab730360e05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/1.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35143e446ea64d029a4cc1360136c73e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model = \"microsoft/phi-2\"\n",
    "new_model = \"/kaggle/working/phi2-mental-health\"\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T16:25:58.237242Z",
     "iopub.status.busy": "2024-07-01T16:25:58.236825Z",
     "iopub.status.idle": "2024-07-01T16:25:58.247479Z",
     "shell.execute_reply": "2024-07-01T16:25:58.246309Z",
     "shell.execute_reply.started": "2024-07-01T16:25:58.237183Z"
    }
   },
   "outputs": [],
   "source": [
    "compute_dtype = torch.float16\n",
    "\n",
    "################################################################################\n",
    "# QLoRA parameters\n",
    "################################################################################\n",
    "\n",
    "# LoRA attention dimension\n",
    "lora_r = 16\n",
    "\n",
    "# Alpha parameter for LoRA scaling\n",
    "lora_alpha = 16\n",
    "\n",
    "# Dropout probability for LoRA layers\n",
    "lora_dropout = 0.5\n",
    "\n",
    "################################################################################\n",
    "# bitsandbytes parameters\n",
    "################################################################################\n",
    "\n",
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float8\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = True\n",
    "\n",
    "################################################################################\n",
    "# TrainingArguments parameters\n",
    "################################################################################\n",
    "\n",
    "# Output directory where the model predictions and checkpoints will be stored\n",
    "output_dir = \"./results\"\n",
    "\n",
    "# Number of training epochs\n",
    "num_train_epochs = 2\n",
    "\n",
    "# Enable fp16/bf16 training (set bf16 to True with an A100)\n",
    "fp16 = False\n",
    "bf16 = False\n",
    "\n",
    "# Batch size per GPU for training\n",
    "per_device_train_batch_size = 1\n",
    "\n",
    "\n",
    "# Number of update steps to accumulate the gradients for\n",
    "gradient_accumulation_steps = 32\n",
    "\n",
    "# Enable gradient checkpointing\n",
    "gradient_checkpointing = True\n",
    "\n",
    "# Maximum gradient normal (gradient clipping)\n",
    "max_grad_norm = 0.3\n",
    "\n",
    "# Initial learning rate (AdamW optimizer)\n",
    "learning_rate = 2e-4\n",
    "\n",
    "# Weight decay to apply to all layers except bias/LayerNorm weights\n",
    "weight_decay = 0.001\n",
    "\n",
    "# Optimizer to use\n",
    "optim = \"paged_adamw_32bit\"\n",
    "\n",
    "# Learning rate schedule\n",
    "lr_scheduler_type = \"cosine\"\n",
    "\n",
    "# Number of training steps (overrides num_train_epochs)\n",
    "max_steps = -1\n",
    "\n",
    "# Ratio of steps for a linear warmup (from 0 to learning rate)\n",
    "warmup_ratio = 0.03\n",
    "\n",
    "# Group sequences into batches with same length\n",
    "# Saves memory and speeds up training considerably\n",
    "group_by_length = True\n",
    "\n",
    "# Save checkpoint every X updates steps\n",
    "save_steps = 0\n",
    "\n",
    "# Log every X updates steps\n",
    "logging_steps = 25\n",
    "\n",
    "################################################################################\n",
    "# SFT parameters\n",
    "################################################################################\n",
    "\n",
    "# Maximum sequence length to use\n",
    "max_seq_length = None\n",
    "\n",
    "# Pack multiple short examples in the same input sequence to increase efficiency\n",
    "packing = False\n",
    "\n",
    "# Load the entire model on the GPU 0\n",
    "device_map = {\"\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T16:25:58.249271Z",
     "iopub.status.busy": "2024-07-01T16:25:58.248837Z",
     "iopub.status.idle": "2024-07-01T16:25:58.263158Z",
     "shell.execute_reply": "2024-07-01T16:25:58.262264Z",
     "shell.execute_reply.started": "2024-07-01T16:25:58.249231Z"
    }
   },
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T16:25:58.264727Z",
     "iopub.status.busy": "2024-07-01T16:25:58.264432Z",
     "iopub.status.idle": "2024-07-01T16:26:23.350169Z",
     "shell.execute_reply": "2024-07-01T16:26:23.349116Z",
     "shell.execute_reply.started": "2024-07-01T16:25:58.264701Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc59f6e1641d4ec3b6dcd1a9d624e9a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/755 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb6749fe56648dba76460b67da58945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_phi.py:   0%|          | 0.00/2.03k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b672e328382b429592de3df2dff83d3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_phi.py:   0%|          | 0.00/33.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f987a17c8d4d40b8150998294521bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/24.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48f63214943b484fa3cf0192e58f201f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f8ab89696a64e3089b9277942b70ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f4d79c91d3406ba6752863a719c338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/577M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab2a13c6a534f9685febf646badba93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "129254b3edba4748884f1ffc03f433f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/69.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load base model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=bnb_config,\n",
    "    trust_remote_code=True,\n",
    "    flash_attn = True,\n",
    "    flash_rotary=True,\n",
    "    fused_dense = True,\n",
    "    device_map=device_map, \n",
    "    revision = \"refs/pr/23\"\n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "model = prepare_model_for_kbit_training(model, use_gradient_checkpointing=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T16:26:23.351721Z",
     "iopub.status.busy": "2024-07-01T16:26:23.351384Z",
     "iopub.status.idle": "2024-07-01T16:26:48.440431Z",
     "shell.execute_reply": "2024-07-01T16:26:48.439591Z",
     "shell.execute_reply.started": "2024-07-01T16:26:23.351678Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:159: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30c8858aac4d49e1b47450a3746a7f78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3512 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load LoRA configuration\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    r=lora_r,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"Wqkv\", \"fc1\", \"fc2\"]    \n",
    ")\n",
    "\n",
    "# Set training parameters\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=\"/kaggle/working/mhGPT\",\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    eval_steps=1000, \n",
    "    evaluation_strategy=\"steps\",\n",
    "    optim=optim,\n",
    "    save_steps=save_steps,\n",
    "    logging_steps=logging_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    fp16=fp16,\n",
    "    bf16=bf16,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    max_steps=max_steps,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    group_by_length=group_by_length,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    report_to=\"tensorboard\"\n",
    ")\n",
    "\n",
    "# Set supervised fine-tuning parameters\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=training_dataset,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing=packing,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T16:26:48.441876Z",
     "iopub.status.busy": "2024-07-01T16:26:48.441555Z",
     "iopub.status.idle": "2024-07-01T17:57:55.932652Z",
     "shell.execute_reply": "2024-07-01T17:57:55.931731Z",
     "shell.execute_reply.started": "2024-07-01T16:26:48.441836Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a CodeGenTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='218' max='218' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [218/218 1:30:01, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=218, training_loss=2.325537147871945, metrics={'train_runtime': 5465.756, 'train_samples_per_second': 1.285, 'train_steps_per_second': 0.04, 'total_flos': 1.633006294493184e+16, 'train_loss': 2.325537147871945, 'epoch': 1.99})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T18:01:44.463913Z",
     "iopub.status.busy": "2024-07-01T18:01:44.463378Z",
     "iopub.status.idle": "2024-07-01T18:01:44.769345Z",
     "shell.execute_reply": "2024-07-01T18:01:44.768288Z",
     "shell.execute_reply.started": "2024-07-01T18:01:44.463849Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/kaggle/working/phi2-mental-health/tokenizer_config.json',\n",
       " '/kaggle/working/phi2-mental-health/special_tokens_map.json',\n",
       " '/kaggle/working/phi2-mental-health/vocab.json',\n",
       " '/kaggle/working/phi2-mental-health/merges.txt',\n",
       " '/kaggle/working/phi2-mental-health/added_tokens.json',\n",
       " '/kaggle/working/phi2-mental-health/tokenizer.json')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.save_pretrained(new_model)\n",
    "trainer.tokenizer.save_pretrained(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T18:02:45.416631Z",
     "iopub.status.busy": "2024-07-01T18:02:45.415988Z",
     "iopub.status.idle": "2024-07-01T18:03:03.512505Z",
     "shell.execute_reply": "2024-07-01T18:03:03.511571Z",
     "shell.execute_reply.started": "2024-07-01T18:02:45.416598Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1270: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] What is a large language model? [/INST] A large language model is a type of artificial intelligence (AI) system that is able to process and understand human language. Large language models are typically used for natural language processing (NLP) tasks such as text generation, machine translation, and sentiment analysis. Some examples of large language models include GPT-3, BERT, and ELMO. These models are trained on large amounts of text data and are able to generate human-like text that is often indistinguishable from that of a human writer. Large language models are a relatively new development in the field of AI and are still being developed and refined. They have the potential to revolutionize many areas of human communication and interaction, but they also raise important ethical and social questions that need to be addressed. For example, how can we ensure that these models are used ethically and responsibly? How can we ensure that they are not used to perpetuate harmful stereotypes or biases? How\n"
     ]
    }
   ],
   "source": [
    "# Ignore warnings\n",
    "logging.set_verbosity(logging.CRITICAL)\n",
    "\n",
    "# Run text generation pipeline with our next model\n",
    "prompt = \"What is a large language model?\"\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200)\n",
    "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
